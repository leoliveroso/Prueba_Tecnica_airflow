[2023-05-02T17:25:18.071+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: prueba_tecnica.transform_data manual__2023-05-02T17:24:07.621819+00:00 map_index=1 [queued]>
[2023-05-02T17:25:18.102+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: prueba_tecnica.transform_data manual__2023-05-02T17:24:07.621819+00:00 map_index=1 [queued]>
[2023-05-02T17:25:18.102+0000] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2023-05-02T17:25:18.103+0000] {taskinstance.py:1284} INFO - Starting attempt 1 of 1
[2023-05-02T17:25:18.103+0000] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2023-05-02T17:25:18.150+0000] {taskinstance.py:1304} INFO - Executing <Mapped(_PythonDecoratedOperator): transform_data> on 2023-05-02 17:24:07.621819+00:00
[2023-05-02T17:25:18.182+0000] {standard_task_runner.py:55} INFO - Started process 1034 to run task
[2023-05-02T17:25:18.193+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'prueba_tecnica', 'transform_data', 'manual__2023-05-02T17:24:07.621819+00:00', '--job-id', '60', '--raw', '--subdir', 'DAGS_FOLDER/data_process/prueba/Prueba_Tecnica.py', '--cfg-path', '/tmp/tmpv6z6f0yy', '--map-index', '1']
[2023-05-02T17:25:18.194+0000] {standard_task_runner.py:83} INFO - Job 60: Subtask transform_data
[2023-05-02T17:25:18.335+0000] {task_command.py:389} INFO - Running <TaskInstance: prueba_tecnica.transform_data manual__2023-05-02T17:24:07.621819+00:00 map_index=1 [running]> on host bb7d79814ac7
[2023-05-02T17:25:18.841+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=loliveros
AIRFLOW_CTX_DAG_ID=prueba_tecnica
AIRFLOW_CTX_TASK_ID=transform_data
AIRFLOW_CTX_EXECUTION_DATE=2023-05-02T17:24:07.621819+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2023-05-02T17:24:07.621819+00:00
[2023-05-02T17:25:18.842+0000] {Prueba_Tecnica.py:120} INFO - Counter: 1 and dim list file path: 2
[2023-05-02T17:25:18.844+0000] {Prueba_Tecnica.py:124} INFO - File path: /tmp/prueba_tecnica/data/raw/collisions_20230502.csv and file path dest: /tmp/prueba_tecnica/data/stage
[2023-05-02T17:25:20.469+0000] {warnings.py:109} WARNING - /opt/***/dags/data_process/prueba/utils/general_utils.py:25: DtypeWarning: Columns (27) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(file_path, sep = sep, encoding = encoding, header = header)

[2023-05-02T17:25:20.842+0000] {taskinstance.py:1772} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/decorators/base.py", line 217, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/python.py", line 192, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/data_process/prueba/Prueba_Tecnica.py", line 143, in transform_data
    clean_transform_data(df = data, subset_columns=['WEATHER'], json_groupby=json_groupby,path_dest = dir_dest)
  File "/opt/airflow/dags/data_process/prueba/utils/general_utils.py", line 42, in clean_transform_data
    aggfunc=json_groupby['aggfunc']
KeyError: 'aggfunc'
[2023-05-02T17:25:20.851+0000] {taskinstance.py:1322} INFO - Marking task as FAILED. dag_id=prueba_tecnica, task_id=transform_data, map_index=1, execution_date=20230502T172407, start_date=20230502T172518, end_date=20230502T172520
[2023-05-02T17:25:20.865+0000] {standard_task_runner.py:100} ERROR - Failed to execute job 60 for task transform_data ('aggfunc'; 1034)
[2023-05-02T17:25:20.933+0000] {local_task_job.py:159} INFO - Task exited with return code 1
[2023-05-02T17:25:20.949+0000] {taskinstance.py:2582} INFO - 0 downstream tasks scheduled from follow-on schedule check
